{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This algorithm was constructed to estimate migration rates of cancer cells within a tumor, based on a phylogeographic \n",
    "reconstruction using single-cell DNA-seq or single-cell CNV data. It is a work in progress. Although it yields reliable\n",
    "results when given simulated data and data from one actual cancer case, modifications to increase its accuracy and\n",
    "flexibility are required. It is not yet clear whether the behavior of actual cancer cells matches the underlying model\n",
    "sufficiently for this algorithm to generate useful results, and the limitations of the method have not yet been fully\n",
    "explored.\n",
    "\n",
    "(March 25, 2020)\n",
    "'''\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from scipy.stats import binned_statistic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sys import exit\n",
    "from statistics import mean, median\n",
    "from scipy import misc\n",
    "from scipy.special import comb as sp_comb\n",
    "\n",
    "\n",
    "class Phylogeny(object):\n",
    "    def __init__(self, phylogeny_name):\n",
    "        self.name = phylogeny_name\n",
    "        self.n2n = {}     # dictionary mapping names onto nodes\n",
    "        self.n2e ={}     # dictionary mapping names onto edges\n",
    "        self.n_ctr = 0     # counter for naming nodes\n",
    "        self.e_ctr = 0     # counter for naming edges\n",
    "        self.L = 0.0     # log-likelihood for this phylogeny\n",
    "        self.psi = [1.0]     # migration rates\n",
    "        self.psi_num = 1     # number of different migration rates (states)\n",
    "        self.em_trans = pd.DataFrame(np.array([[0.0, -50.0],[-50.0,0.0]]))     \n",
    "            # transition probabilities among migration states\n",
    "        self.migr_priors = None\n",
    "        self.mutn_num = 1     # number of types of mutational changes possible\n",
    "        self.mutn_rate = [0.0]     # mutation rates, one per type of mutation\n",
    "        self.root = None\n",
    "        self.angles = None\n",
    "        self.omni = 0.0\n",
    "        \n",
    "        #self.m = [0.0 for x in range(migr_states)]     # current estimates of migration rates\n",
    "                                                       #    for each migration phenotype\n",
    "        #self.priors = []     # DataFrame: priors for the states for each CNV\n",
    "        #self.m_priors = [1/float(migr_states)for x in range(migr_states)]\n",
    "        #self.root = 0\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "class Node(object):\n",
    "    def __init__(self, node_name):\n",
    "        \"\"\" \n",
    "        node_name: string\n",
    "        Initializes a node. \n",
    "        Name is a string representing the name of this node,\n",
    "        parent is None, and no children exist.\n",
    "        i: number of characters\n",
    "        states: list containing the labels for the character states, as strings\n",
    "        \"\"\"        \n",
    "        self.name = node_name\n",
    "        self.anc_edge = None  # edge leading to the ancestor of this node\n",
    "        self.desc_edges = []  # edges leading to the descendants of this node\n",
    "        self.location = (0.0,0.0)  # spatial x,y coordinates of this node\n",
    "        self.flag = False   # for tracking which nodes have been updated during a traversal\n",
    "        self.time = 0.0     # time before present\n",
    "        self.duct = 'X'\n",
    "        \n",
    "        # self.loc_variance = 0\n",
    "        # self.included = True     # in case estimates of some nodes are negligible\n",
    "        # self.time = (0,0)     # best estimate and variance\n",
    "        # self.f = None\n",
    "        # self.migr_P = None\n",
    "        #self.states = states\n",
    "        #self.chars = pd.DataFrame([[0.0 for x in range(i)]for y in states], index = states) \n",
    "        #self.location = (0,0,0)     # best estimate of x,y,z-coords\n",
    "        #self.migr_Ps = [0.0 for x in range(migr_states)]\n",
    "        #self.b = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name  \n",
    "    \n",
    "class Edge(object):\n",
    "    def __init__(self, p, edge_name, anc_node, desc_node):\n",
    "        self.name = edge_name\n",
    "        self.anc = anc_node\n",
    "        self.desc = desc_node\n",
    "        self.time = anc_node.time - desc_node.time  # the duration of time spent on this branch\n",
    "        self.dist = (((anc_node.location[0]-desc_node.location[0])**2 +\n",
    "                      (anc_node.location[1]-desc_node.location[1])**2)**0.5)\n",
    "    \n",
    "        self.bk_anc = [0.0 for i in range(p.psi_num)]    # b-sub-k, backwards algorithm values, headed toward root\n",
    "        self.bk_desc = [0.0 for i in range(p.psi_num)]    # b-sub-k, backwards algorithm values, headed toward tips\n",
    "        self.marginals = [0.0 for i in range(p.psi_num)]    # marginal probabilities for each migration state for this edge\n",
    "        self.normalized_marginals = [1.0/p.psi_num for i in range(p.psi_num)]    # normalized to sum to 1\n",
    "        self.mutations = 0\n",
    "        self.angle = get_angle(anc_node.location, desc_node.location)   # note that this is from the perspective of \n",
    "                                                                        # the ancestral node!\n",
    "        \n",
    "         #self.migr_state = [0.0 for i in range(p.psi_num)]             # probability that this branch \n",
    "                                                                        # was traversed in each of the two migration phenotypes,\n",
    "                                                                        # 0 = epithelial, 1 = mesenchymal\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "\n",
    "class Control_Panel(object):\n",
    "    \"\"\"\n",
    "    For passing settings and initial states to the reconstruction algorithms.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.psi = [0.0, 0.0]  # migration rates\n",
    "        self.em_trans = pd.DataFrame(np.array([[0.0, -50.0],[-50.0,0.0]]))  # transition probabilities\n",
    "        self.migr_priors = [math.log(0.5), math.log(0.5)]\n",
    "        self.mutation_rate = [0.0]\n",
    "        self.null_location = [0.0, 0.0]\n",
    "        self.null_time = 0.0\n",
    "        self.initialize_locations = 'random'\n",
    "        self.mutation_pseudocount = 1\n",
    "        self.min_edge_time = 0.1\n",
    "        self.location_epsilon = 0.0001\n",
    "        self.location_step = 0.5\n",
    "        self.L_epsilon = 0.001\n",
    "        self.initial_percentage_epithelial = 95\n",
    "        self.psi_epsilon = 0.001\n",
    "        self.time_epsilon = 0.001\n",
    "        self.iter_limit = 500\n",
    "        self.time_step = 0.005\n",
    "        self.space_sigma = 200.0\n",
    "        self.time_sigma = 0.1\n",
    "        self.sigma_T = 1.0\n",
    "        self.sigma_T_step = 0.95\n",
    "        self.exp_T_init = 1.0\n",
    "        self.exp_T = self.exp_T_init\n",
    "        self.exp_T_stop = -3.0\n",
    "        self.exp_T_step = (self.exp_T_init - self.exp_T_stop)/self.iter_limit\n",
    "        self.omni = False\n",
    "        self.acceptance = 'top'\n",
    "        self.correction = 0.0\n",
    "        self.corr2 = 1.0\n",
    "        self.now = False\n",
    "        self.set_psi_num = 1\n",
    "    \n",
    "    def __str__(self):\n",
    "        return None\n",
    "    \n",
    "    def get_step(self, axis):\n",
    "        \n",
    "        if axis == -1:\n",
    "            return (abs(np.random.normal(0, self.time_sigma*self.sigma_T)))\n",
    "        \n",
    "        else:\n",
    "            return (abs(np.random.normal(0, self.space_sigma*self.sigma_T)))\n",
    "\n",
    "    \n",
    "class Proposal(object):\n",
    "    \"\"\"\n",
    "    For proposing node movements in space or time during optimization.\n",
    "    \"\"\"\n",
    "    def __init__(self, ctr, p2, node):\n",
    "        self.name = 'pr'+str(ctr)\n",
    "        self.node = node\n",
    "        self.location = node.location\n",
    "        self.time = node.time\n",
    "        self.de0_time = node.desc_edges[0].time\n",
    "        self.de0_dist = node.desc_edges[0].dist\n",
    "        self.de1_time = node.desc_edges[1].time\n",
    "        self.de1_dist = node.desc_edges[1].dist\n",
    "        \n",
    "        if node.anc_edge == None:\n",
    "            self.ae_time = None\n",
    "            self.ae_dist = None\n",
    "            \n",
    "        else:\n",
    "            self.ae_time = node.anc_edge.time\n",
    "            self.ae_dist = node.anc_edge.dist\n",
    "            \n",
    "        self.angles = []\n",
    "        self.omni = 0.0\n",
    "        \n",
    "        self.L = 0.0\n",
    "        \n",
    "\n",
    "def text_to_array(FILENAME):\n",
    "    inFile = open(FILENAME, 'r')\n",
    "    line = inFile.read()\n",
    "    array = []\n",
    "    while (1):\n",
    "        nextStart = line.find('\\n')\n",
    "        if nextStart == -1:\n",
    "\n",
    "            temp1 = line\n",
    "            if temp1 != '':\n",
    "                array.append(temp1)\n",
    "                \n",
    "            return array\n",
    "            \n",
    "        else:\n",
    "            temp1 = line[:nextStart]\n",
    "            array.append(temp1)\n",
    "            if (nextStart+1) > len(line):\n",
    "                return array\n",
    "            \n",
    "            else:\n",
    "                temp2 = line[nextStart+1:]\n",
    "                line = temp2\n",
    "                \n",
    "def accept_proposal(p2, cp, pr):\n",
    "    n = pr.node\n",
    "    n.location = pr.location\n",
    "    n.time = pr.time\n",
    "    n.desc_edges[0].time = pr.de0_time\n",
    "    n.desc_edges[0].dist = pr.de0_dist\n",
    "    n.desc_edges[1].time = pr.de1_time\n",
    "    n.desc_edges[1].dist = pr.de1_dist\n",
    "    if n.anc_edge != None:\n",
    "        n.anc_edge.time = pr.ae_time\n",
    "        n.anc_edge.dist = pr.ae_dist\n",
    "    \n",
    "    if cp.omni == True:\n",
    "        p2.angles = pr.angles[:]\n",
    "        p2.omni = pr.omni\n",
    "    \n",
    "    return (p2)\n",
    "\n",
    "\n",
    "def branch_dist(a_locn, b_locn):\n",
    "    return (((a_locn[0]-b_locn[0])**2 +\n",
    "         (a_locn[1]-b_locn[1])**2)**0.5)\n",
    "         \n",
    "\n",
    "def clear_phylogeny (p, cp):\n",
    "    p2 = copy.deepcopy(p)\n",
    "    p2.name = 'Ph2'\n",
    "    p2.L = 0.0\n",
    "    p2.psi = cp.psi\n",
    "    p2.em_trans = cp.em_trans\n",
    "    p2.migr_priors = cp.migr_priors[:]\n",
    "    p2.mutn_rate = cp.mutation_rate\n",
    "    \n",
    "    for edge in p2.n2e.values():\n",
    "        edge.bk_anc = [0.0 for i in range(p2.psi_num)]\n",
    "        edge.bk_desc = [0.0 for i in range(p2.psi_num)]\n",
    "        edge.marginals = [0.0 for i in range(p2.psi_num)]\n",
    "        \n",
    "    return (p2)\n",
    "\n",
    "\n",
    "def emission(cp, e, psi):\n",
    "    \"\"\"\n",
    "    e.time: edge length, in terms of time\n",
    "    e.dist: distance between ancestral and descendant nodes for this edge\n",
    "    psi: variance in descendant position, scaled by generation time\n",
    "    \n",
    "    Takes a single value for psi; calculates the probability of seeing e.dist given e.time and psi\n",
    "    \"\"\"\n",
    "    if e.dist == 0:\n",
    "        return (0.0)\n",
    "\n",
    "    f1 = math.log(e.dist)\n",
    "    f2 = math.log(e.time)+2*math.log(psi)\n",
    "    f3 = (e.dist**2)/(2*e.time*(psi**2))\n",
    "    \n",
    "    f = (f1 - f2 - f3)\n",
    "    return (f)\n",
    "\n",
    "\n",
    "def emission_hypothetical(cp, distance, time, psi):\n",
    "    f1 = math.log(distance)\n",
    "    f2 = math.log(time) + 2*math.log(psi)\n",
    "    f3 = (distance**2)/(2*time*(psi**2))\n",
    "    \n",
    "    f = (f1 - f2 - f3)\n",
    "    return (f)\n",
    "\n",
    "\n",
    "def estimate_parameters(cp, p2):\n",
    "    sums = [0.0 for i in range(p2.psi_num)]\n",
    "    wts = [0.0 for i in range(p2.psi_num)]     # these are the sums across all edges for the normalized marginals, i.e., \n",
    "                         #    when normalized, they are the proportion of the time that the lineages\n",
    "                         #    are probably in each state\n",
    "    \n",
    "\n",
    "    for e in p2.n2e.values():\n",
    "        \n",
    "        if p2.psi_num > 1:\n",
    "            try:\n",
    "                mdiff = math.exp(e.marginals[0]-e.marginals[1])\n",
    "                \n",
    "            except:\n",
    "                print (e.marginals[0], e.marginals[1])\n",
    "                exit(0)\n",
    "                \n",
    "            mpr = [mdiff/(mdiff+1), 1/(mdiff+1)]\n",
    "            if (mpr[0]==0):\n",
    "                mpr[0]=1/10**10\n",
    "                mpr[1]=1 - mpr[0]\n",
    "\n",
    "            if (mpr[1]==0):\n",
    "                mpr[1]=1/10**10\n",
    "                mpr[0]=1 - mpr[1]\n",
    "                \n",
    "            e.normalized_marginals = mpr     # note that these are likelihoods, not log-likelihoods!\n",
    "                \n",
    "        else:\n",
    "            e.normalized_marginals = [1.0]\n",
    "            \n",
    "        \n",
    "        \n",
    "        for i in range(p2.psi_num):\n",
    "            p2 = estimate_psi_v2(cp, p2, i)\n",
    "   \n",
    "    temp_np = [sum([e.normalized_marginals[i] for e in p2.n2e.values()]) for i in range(p2.psi_num)]\n",
    "    new_priors = [math.log(temp_np[i]/sum(temp_np)) for i in range(p2.psi_num)]\n",
    "    \n",
    "    em_trans_temp = pd.DataFrame(np.array([[0.0, 0.0],[0.0,0.0]]))\n",
    "    em_trans_temp_wts = [0.0, 0.0]\n",
    "    internal_nodes = [a for a in p2.n2n.values() if len(a.desc_edges) > 0]\n",
    "    for n in internal_nodes:\n",
    "        states_k = [de.normalized_marginals for de in n.desc_edges]\n",
    "        if n.anc_edge == None:\n",
    "            states_j = [math.exp(new_priors[i]) for i in range(len(new_priors))]\n",
    "            \n",
    "        else:\n",
    "            states_j = n.anc_edge.normalized_marginals\n",
    "            \n",
    "        for anc_state in range(p2.psi_num):\n",
    "            for desc_state in range(p2.psi_num):\n",
    "                for de in range(2):\n",
    "                    em_trans_temp.iloc[anc_state, desc_state]+=(states_j[anc_state]*states_k[de][desc_state])\n",
    "                    em_trans_temp_wts[anc_state]+=states_j[anc_state]\n",
    "                    \n",
    "    em_trans_temp2 = pd.DataFrame(np.array([[(em_trans_temp.loc[j, k]/em_trans_temp_wts[j]) \n",
    "                                           for k in range(p2.psi_num)] for j in range(p2.psi_num)]))\n",
    "    \n",
    "    em_trans_new = pd.DataFrame(np.array([[math.log(em_trans_temp2.loc[j,k]/sum(em_trans_temp2.loc[j,:]))\n",
    "                                           for k in range(p2.psi_num)] for j in range(p2.psi_num)]))\n",
    "    \n",
    "    return (p2, new_priors, em_trans_new)\n",
    "\n",
    "\n",
    "def estimate_psi_v2(cp, p2, i):\n",
    "    #print (i)\n",
    "    direction = -1\n",
    "    step = 1\n",
    "    epsilon = 0.001\n",
    "    psi_temp = p2.psi[i]\n",
    "    L_sum = 0.0\n",
    "    L_wts = 0.0\n",
    "    for e in p2.n2e.values():\n",
    "        L_sum += e.normalized_marginals[i]*emission(cp, e, psi_temp)\n",
    "        L_wts += e.normalized_marginals[i]\n",
    "\n",
    "    try:\n",
    "        L_old = L_sum/L_wts\n",
    "\n",
    "    except ZeroDivisionError:\n",
    "        p2.psi[i] = 1.0\n",
    "        return (p2)\n",
    "    \n",
    "    L_orig = L_old\n",
    "    psi_temp += (direction*step)\n",
    "    while True:\n",
    "        L_sum = 0.0\n",
    "        L_wts = 0.0\n",
    "        for e in p2.n2e.values():\n",
    "            L_sum += e.normalized_marginals[i]*emission(cp, e, psi_temp)\n",
    "            L_wts += e.normalized_marginals[i]\n",
    "            \n",
    "        try:\n",
    "            L_new = L_sum/L_wts\n",
    "            \n",
    "        except ZeroDivisionError:\n",
    "            p2.psi[i] = 1.0\n",
    "            return (p2)\n",
    "        \n",
    "        if (abs(L_new - L_old) < epsilon):\n",
    "            p2.psi[i] = psi_temp #*cp.corr2\n",
    "            \n",
    "            return (p2)\n",
    "        \n",
    "        else:\n",
    "            if L_new > L_old:\n",
    "                psi_temp += (direction*step)\n",
    "                \n",
    "            else:\n",
    "                direction *= -1\n",
    "                step /= 2\n",
    "                psi_temp += (direction*step)\n",
    "                \n",
    "            L_old = L_new\n",
    "\n",
    "def estimate_psi_v3(cp, p2, i):\n",
    "    #print (i)\n",
    "    direction = 1\n",
    "    step = 10\n",
    "    epsilon = 0.1\n",
    "    L_old = -10000000\n",
    "    p_temp = copy.deepcopy(p2)\n",
    "    while True:\n",
    "        p_temp2 = get_L(cp, p_temp)\n",
    "        L_new = p_temp2.L\n",
    "        print (L_old, L_new)\n",
    "        if (abs(L_new - L_old) < epsilon):\n",
    "            p2.psi[i] = p_temp2.psi[i]\n",
    "            return (p2)\n",
    "        \n",
    "        else:\n",
    "            p_temp = copy.deepcopy(p_temp2)\n",
    "            if L_new > L_old:\n",
    "                p_temp.psi[i] += (direction*step)\n",
    "                \n",
    "            else:\n",
    "                direction *= -1\n",
    "                step /= 2\n",
    "                p_temp.psi[i] += (direction*step)\n",
    "                \n",
    "            L_old = L_new\n",
    "        \n",
    "            \n",
    "def estimate_times (p2, cp):\n",
    "    # initialize times for internal nodes based on number of mutations along branches\n",
    "    # estimate times for edges\n",
    "    def et_recursion (node):\n",
    "        if node.desc_edges == []:\n",
    "            node.time = 0.0\n",
    "            return (node.time)\n",
    "        \n",
    "        else:\n",
    "            mutn_ct = 0.0\n",
    "            for e in node.desc_edges:\n",
    "                mutn_ct += float(e.mutations + cp.mutation_pseudocount)\n",
    "                mutn_ct += float(et_recursion(e.desc))\n",
    "                \n",
    "            temp = [(e.desc.time+cp.min_edge_time) for e in node.desc_edges]\n",
    "            temp.append(mutn_ct/2.0)\n",
    "            node.time = max (temp)\n",
    "            return (node.time)\n",
    "    \n",
    "    for node in p2.n2n.values():\n",
    "        node.time = cp.null_time\n",
    "        \n",
    "    for edge in p2.n2e.values():\n",
    "        edge.time = 0.0\n",
    "        \n",
    "    temp1 = et_recursion(p2.root)\n",
    "    for n in p2.n2n.values():\n",
    "        n.time /= temp1\n",
    "      \n",
    "    p2.mutn_rate = temp1   \n",
    "    for e in p2.n2e.values():\n",
    "        e.time = e.anc.time - e.desc.time\n",
    "\n",
    "    return (p2)\n",
    "\n",
    "\n",
    "def fbb2(cp, p):\n",
    "        \n",
    "    def to_tips(cp, p, edge, fd_node):\n",
    "        \"\"\"\n",
    "        Returns the total probability of all paths that lead to all tips not descended from this edge, to \n",
    "        starting this edge in migration state k.\n",
    "        \"\"\"\n",
    "        sibling = get_sibling(edge, edge.anc.desc_edges)\n",
    "        for j in range (p.psi_num):\n",
    "            fd_node[j] += mult_logaddexp([(sibling.bk_anc[k]+p.em_trans.loc[j][k]) for k in range(p.psi_num)])\n",
    "\n",
    "        edge.bk_desc = [0.0 for i in range(p.psi_num)]\n",
    "        \n",
    "        for l in range(p.psi_num):\n",
    "            edge.bk_desc[l] += mult_logaddexp([(fd_node[j]+p.em_trans.loc[j][l]) for j in range(p.psi_num)])\n",
    "            \n",
    "        edge.marginals = [(edge.bk_anc[i] + edge.bk_desc[i] - p.L) for i in range(p.psi_num)]\n",
    "                     \n",
    "        if edge.desc.desc_edges == []:\n",
    "            return (p)\n",
    "        \n",
    "        else:\n",
    "            for k in range(p.psi_num):\n",
    "                edge.bk_desc[k] += emission(cp, edge, p.psi[k])\n",
    "                \n",
    "            for new_edge in edge.desc.desc_edges:\n",
    "                p = to_tips(cp, p, new_edge, edge.bk_desc)\n",
    "                \n",
    "            return (p)\n",
    "            \n",
    "            sibling = get_sibling(edge, edge.anc.desc_edges)\n",
    "            for j in range (p.psi_num):\n",
    "                fd_node[j] += mult_logaddexp([(sibling.bk_anc[k]+p.em_trans.loc[j][k]) for k in range(p.psi_num)])\n",
    "                \n",
    "            edge.bk_desc = [0.0 for i in range(p.psi_num)]\n",
    "            for l in range(p.psi_num):\n",
    "                edge.bk_desc[l] += mult_logaddexp([(fd_node[j]+p.em_trans.loc[j][l]) for j in range(p.psi_num)])\n",
    "                \n",
    "        \n",
    "    \n",
    "    p = get_L (cp, p)\n",
    "    \n",
    "    for new_edge in p.root.desc_edges:\n",
    "        p = to_tips(cp, p, new_edge, p.migr_priors[:])\n",
    "\n",
    "    return (p)\n",
    "\n",
    "\n",
    "def get_angle (a,b):\n",
    "    \"\"\"\n",
    "    Returns the angle of a line between points a and b (from a's perspective!).\n",
    "    Returns values between 0 and 2*pi.\n",
    "    \"\"\"\n",
    "    return (np.arctan2(b[1]-a[1], b[0]-a[0]))%(2*math.pi)\n",
    "\n",
    "\n",
    "def angle_between (desc_angle,anc_angle):\n",
    "    return (desc_angle-anc_angle)%(2*math.pi)\n",
    "    \n",
    "\n",
    "def get_distances (location, neighbor_locations):\n",
    "    return ([branch_dist(location, n) for n in neighbor_locations])\n",
    "\n",
    "\n",
    "def get_L(cp, p):\n",
    "    #bk_root = [0.0 for i in range(p.psi_num)]\n",
    "    bk_root = p.migr_priors[:]\n",
    "    for desc_edge in p.root.desc_edges:     # for each descendant edge:\n",
    "        p, bk_temp = to_root(cp, p, desc_edge)     # get bk_anc for that edge\n",
    "        for j in range (p.psi_num):     # for each possible state at the root of the phylogeny:\n",
    "            tempj = mult_logaddexp([(bk_temp[k]+p.em_trans.loc[j][k]) for k in range(p.psi_num)])\n",
    "            bk_root[j] += tempj\n",
    "                 # sum over the possible paths that lead to starting the phylogeny in state j\n",
    "                \n",
    "    p.L = mult_logaddexp(bk_root)     # this is the total probability across all paths and states\n",
    "    \n",
    "    return(p)\n",
    "\n",
    "\n",
    "def get_L_local (cp, p2, edges, distances, times, psi, to_optimize = 'location'):\n",
    "    L_temp = 0.0\n",
    "    for i in range(len(edges)):\n",
    "        L_temp += mult_logaddexp([((emission_hypothetical(cp, distances[i],\n",
    "                times[i],psi[k]))+math.log(edges[i].normalized_marginals[k])) for k in range(p2.psi_num)])\n",
    "            \n",
    "    return (L_temp)\n",
    "\n",
    "\n",
    "def get_proposal(p2, cp, pr_ctr, node, axis, direction, step):\n",
    "    pr = Proposal(pr_ctr, p2, node)\n",
    "    if (axis == -1):\n",
    "        pr.de0_time += (direction*step)\n",
    "        pr.de1_time += (direction*step)\n",
    "        temp = [pr.de0_time, pr.de1_time]\n",
    "        if node.anc_edge != None:\n",
    "            pr.ae_time -= (direction*step)\n",
    "            temp.append(pr.ae_time)\n",
    "            \n",
    "        if (min(temp)<0):\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            edges = [de for de in node.desc_edges if de.dist != 0]\n",
    "            distances = [de.dist for de in node.desc_edges if de.dist != 0]\n",
    "            if node.anc_edge != None:\n",
    "                if node.anc_edge.dist != 0:\n",
    "                    edges.append(node.anc_edge)\n",
    "                    distances.append(node.anc_edge.dist)\n",
    "                \n",
    "            times = temp \n",
    "            L_temp = get_L_local (cp, p2, edges, distances, times, p2.psi, to_optimize = 'time')\n",
    "            if cp.omni == True:\n",
    "                L_temp += p2.omni\n",
    "                pr.omni = p2.omni\n",
    "                pr.angles = p2.angles\n",
    "                \n",
    "            pr.time = node.time + (direction*step)\n",
    "            \n",
    "    else:\n",
    "        edges = [e for e in node.desc_edges if e.dist != 0]\n",
    "        times = [de.time for de in node.desc_edges if de.dist != 0]\n",
    "        neighbor_locations = [de.desc.location for de in node.desc_edges if de.dist != 0]\n",
    "        if node.anc_edge != None:\n",
    "            if node.anc_edge.dist != 0:\n",
    "                edges.append(node.anc_edge)\n",
    "                times.append(node.anc_edge.time)\n",
    "                neighbor_locations.append(node.anc_edge.anc.location)\n",
    "            \n",
    "        x_new = node.location[0] + ((direction*step)*abs(axis-1))\n",
    "        y_new = node.location[1] + ((direction*step)*axis)\n",
    "        new_distances = get_distances((x_new, y_new), neighbor_locations)\n",
    "        L_temp = get_L_local (cp, p2, edges, new_distances, times, p2.psi)\n",
    "        pr.location = (x_new, y_new)\n",
    "        pr.de0_dist, pr.de1_dist = new_distances[0], new_distances[1]\n",
    "        if node.anc_edge != None:\n",
    "            pr.ae_dist = new_distances[2]\n",
    "         \n",
    "        if cp.omni == True:\n",
    "            involved = [de.desc.name for de in node.desc_edges]\n",
    "            involved.append(node.name)\n",
    "            if node.anc_edge != None:\n",
    "                involved.append(node.anc_edge.anc.name)\n",
    "\n",
    "            temp_angles = p2.angles.loc[~p2.angles['node'].isin(involved)][:]\n",
    "\n",
    "            de0 = node.desc_edges[0].desc\n",
    "            if node.anc_edge == None:\n",
    "                anc_temp = None\n",
    "\n",
    "            else:\n",
    "                anc_temp = node.anc_edge.anc\n",
    "\n",
    "            angles_add = get_proposed_angles(node, pr.location, anc_temp, \n",
    "                                                 node.desc_edges[0].desc, node.desc_edges[1].desc)\n",
    "\n",
    "            pr.angles = pd.concat([temp_angles, angles_add])\n",
    "            pval, m = omnibus(np.array(pr.angles.loc[:,'angle']))\n",
    "            pr.omni = math.log(pval)\n",
    "            L_temp += pr.omni\n",
    "        \n",
    "                         \n",
    "    pr.L = L_temp\n",
    "    return (pr)\n",
    "\n",
    "\n",
    "def get_proposed_angles(node, proposed_loc, anc, de0, de1):\n",
    "    nde0 = get_angle(proposed_loc, de0.location)\n",
    "    nde1 = get_angle(proposed_loc, de1.location)\n",
    "    nodes = [node.name]\n",
    "    angles = [angle_between(nde0, nde1)]\n",
    "    if node.anc_edge != None:\n",
    "        nanc = get_angle(anc.location, proposed_loc)\n",
    "        angles.append(angle_between(nde0, nanc))\n",
    "        angles.append(angle_between(nde1, nanc))\n",
    "        nodes *= 3\n",
    "        temp = [(nanc+math.pi)%(2*math.pi)]\n",
    "        temp.append(get_sibling(node.anc_edge, node.anc_edge.anc.desc_edges).angle)\n",
    "        if anc.anc_edge != None:\n",
    "            temp.append((anc.anc_edge.angle+math.pi)%(2*math.pi))\n",
    "            for i in range(len(temp)-1):\n",
    "                for j in range(i+1, len(temp)):\n",
    "                    angles.append(angle_between(temp[j],temp[i]))\n",
    "                    nodes.append(anc.name)\n",
    "        \n",
    "    for de in [de0, de1]:\n",
    "        temp = [dde.angle for dde in de.desc_edges]\n",
    "        temp.append (get_angle(de.location, proposed_loc))\n",
    "        for i in range(len(temp)-1):\n",
    "            for j in range(i+1, len(temp)):\n",
    "                angles.append(angle_between(temp[j],temp[i]))\n",
    "                nodes.append(de.name)\n",
    "                \n",
    "    new_angles = pd.DataFrame({'node':nodes,'angle':angles})\n",
    "    return (new_angles)       \n",
    "        \n",
    "\n",
    "def get_sibling(edge, desc_edges):\n",
    "    temp = desc_edges[:]\n",
    "    temp.remove(edge)\n",
    "    return (temp[0])\n",
    "\n",
    "\n",
    "def initialize_angles_df(p2):\n",
    "    # initialize the list of angles stored (by associated node) in the Phylogeny object for\n",
    "    # the omnibus function\n",
    "    nodes = []\n",
    "    angles = []\n",
    "    internal_nodes = [a for a in p2.n2n.values() if len(a.desc_edges) > 0]\n",
    "    for a in internal_nodes:\n",
    "        temp = []\n",
    "        if a.anc_edge != None:\n",
    "            temp.append((a.anc_edge.angle+math.pi)%(2*math.pi))\n",
    "            \n",
    "        for de in a.desc_edges:\n",
    "            temp.append(de.angle)\n",
    "  \n",
    "        for i in range(len(temp)-1):\n",
    "            for j in range(i+1, len(temp)):\n",
    "                angles.append(angle_between(temp[i],temp[j]))\n",
    "                nodes.append(a.name)\n",
    "                \n",
    "    p2.angles = pd.DataFrame({'node':nodes,'angle':angles})\n",
    "    pval, m = omnibus(np.array(p2.angles.loc[:,'angle']))\n",
    "    p2.omni = math.log(pval)\n",
    "    return (p2)\n",
    "\n",
    "\n",
    "def initialize_locations_descendants (p2, cp):\n",
    "    # initialize locations of internal nodes at a position on the line between their descendants,\n",
    "    #     with distances from each descendant proportional to the amount of time \n",
    "    # initialize distances for edges based on these locations\n",
    "    \n",
    "    def ild_recursion(node):\n",
    "        if node.desc_edges == []:\n",
    "            return (node.anc_edge, node.location)\n",
    "        \n",
    "        else:\n",
    "            de = [None, None]\n",
    "            desc_locns = [[0.0, 0.0], [0.0, 0.0]]\n",
    "            for i in range (2):\n",
    "                de[i], desc_locns[i] = ild_recursion(node.desc_edges[i].desc)\n",
    "                \n",
    "            b_root = [(e.time**0.5) for e in de]\n",
    "            b_ratio = [b_root[i]/sum(b_root) for i in range(2)]\n",
    "            x_new = desc_locns[0][0]+(b_ratio[0]*(desc_locns[1][0]-desc_locns[0][0]))\n",
    "            y_new = desc_locns[0][1]+(b_ratio[0]*(desc_locns[1][1]-desc_locns[0][1]))\n",
    "            \n",
    "            node.location = [x_new, y_new]\n",
    "            return (node.anc_edge, node.location)\n",
    "        \n",
    "    internal_nodes = [a for a in p2.n2n.values() if len(a.desc_edges) > 0]\n",
    "    for a in internal_nodes:\n",
    "        a.location = cp.null_location\n",
    "        \n",
    "    temp1, temp2 = ild_recursion(p2.root)\n",
    "    \n",
    "    for e in p2.n2e.values():\n",
    "        e.dist = (((e.anc.location[0]-e.desc.location[0])**2 +\n",
    "                      (e.anc.location[1]-e.desc.location[1])**2)**0.5)\n",
    "        \n",
    "        e.angle = get_angle(e.anc.location, e.desc.location)\n",
    "        \n",
    "    if cp.omni == True:\n",
    "        p2 = initialize_angles_df(p2)\n",
    "        \n",
    "    return (p2)\n",
    "\n",
    "\n",
    "def initialize_locations_random (p2, cp):\n",
    "    # initialize locations of internal nodes with a random uniform distribution between\n",
    "    #     the min and max of the tip nodes in each dimension\n",
    "    # initialize distances for edges based on these locations\n",
    "    \n",
    "    x_range = [a.location[0] for a in p2.n2n.values()]\n",
    "    y_range = [a.location[1] for a in p2.n2n.values()]\n",
    "\n",
    "    internal_nodes = [a for a in p2.n2n.values() if len(a.desc_edges) > 0]\n",
    "\n",
    "    for a in internal_nodes:\n",
    "        a.location = (random.uniform(min(x_range), max(x_range)),random.uniform(min(y_range), max(y_range)))\n",
    "        \n",
    "    for e in p2.n2e.values():\n",
    "        e.dist = (((e.anc.location[0]-e.desc.location[0])**2 +\n",
    "                      (e.anc.location[1]-e.desc.location[1])**2)**0.5)\n",
    "        \n",
    "        e.angle = get_angle(e.anc.location, e.desc.location)\n",
    "        \n",
    "    if cp.omni == True:\n",
    "        p2 = initialize_angles_df(p2)\n",
    "        \n",
    "    return (p2)\n",
    "\n",
    "\n",
    "def initialize_psi (p2, cp):\n",
    "    psi_temp = [math.log(e.dist/(e.time**0.5)) for e in p2.n2e.values()]\n",
    "    psi_temp = sorted(psi_temp)\n",
    "    if p2.psi_num == 2:\n",
    "        # based on edge distances and times, initialize psi\n",
    "        cutoff = np.percentile(psi_temp, cp.initial_percentage_epithelial)\n",
    "        psi_e = (mean([math.exp(i) for i in psi_temp if i < cutoff]))\n",
    "        psi_m = (mean([math.exp(i) for i in psi_temp if i >= cutoff]))\n",
    "        p2.psi = [psi_e, psi_m]\n",
    "        return (p2)\n",
    "    \n",
    "    elif p2.psi_num == 1:\n",
    "        p2.psi = [mean([math.exp(i) for i in psi_temp])]\n",
    "        return (p2)\n",
    "\n",
    "def initialize_sigmas (p2, cp):\n",
    "    x_range = [a.location[0] for a in p2.n2n.values()]\n",
    "    y_range = [a.location[1] for a in p2.n2n.values()]\n",
    "    cp.space_sigma = ((max(x_range)-min(x_range)) + (max(y_range)-min(y_range)))/20\n",
    "    cp.time_sigma = 0.01\n",
    "    \n",
    "    return (p2, cp)\n",
    "\n",
    "\n",
    "def insert_node(p, node_to_add, tip_node, edge_to_split, e_counter):\n",
    "    total_time = edge_to_split.time\n",
    "    descendant = edge_to_split.desc\n",
    "    \n",
    "    p.n2e[e_counter+1]=Edge(p, 'e'+str(e_counter+1), edge_to_split.anc, node_to_add)   # new branch: bottom half of edge_to_split\n",
    "    p.n2e[e_counter+1].marginals = edge_to_split.marginals\n",
    "    edge_to_split.anc.desc_edges.remove(edge_to_split)\n",
    "    edge_to_split.anc.desc_edges.append(p.n2e[e_counter+1])\n",
    "    node_to_add.anc_edge = p.n2e[e_counter+1]\n",
    "    \n",
    "    edge_to_split.anc = node_to_add\n",
    "    a = math.log(np.random.uniform(0.0,1.0))\n",
    "    if a <(p.em_trans.iloc[np.argmax(p.n2e[e_counter+1].marginals)]\n",
    "                                   [abs(np.argmax(p.n2e[e_counter+1].marginals) - 1)]):\n",
    "        edge_to_split.marginals = [p.n2e[e_counter+1].marginals[1],p.n2e[e_counter+1].marginals[0]]     # toggle migr_state\n",
    "    \n",
    "    p.n2e[e_counter]=Edge(p, 'e'+str(e_counter), node_to_add, tip_node)\n",
    "    tip_node.anc_edge=p.n2e[e_counter]\n",
    "    p.n2e[e_counter].marginals = p.n2e[e_counter+1].marginals\n",
    "    a = math.log(np.random.uniform(0.0,1.0))\n",
    "    if a <(p.em_trans.iloc[np.argmax(p.n2e[e_counter+1].marginals)]\n",
    "                                   [abs(np.argmax(p.n2e[e_counter+1].marginals) - 1)]):\n",
    "        edge_to_split.marginals = [p.n2e[e_counter+1].marginals[1],p.n2e[e_counter+1].marginals[0]]     # toggle migr_state\n",
    "    \n",
    "    node_to_add.desc_edges = [p.n2e[e_counter],edge_to_split]\n",
    "    \n",
    "    e_counter += 2\n",
    "    \n",
    "    return (e_counter)\n",
    "\n",
    "\n",
    "def mult_logaddexp(P_array):\n",
    "    lae = P_array[0]\n",
    "    for x in range(1,len(P_array)):\n",
    "        lae = np.logaddexp(lae,P_array[x])\n",
    "        \n",
    "    return lae\n",
    "\n",
    "\n",
    "def omnibus(alpha, w=None, sz=np.radians(1), axis=None):\n",
    "    \"\"\"\n",
    "    Computes omnibus test for non-uniformity of circular data. The test is also\n",
    "    known as Hodges-Ajne test.\n",
    "    H0: the population is uniformly distributed around the circle\n",
    "    HA: the populatoin is not distributed uniformly around the circle\n",
    "    Alternative to the Rayleigh and Rao's test. Works well for unimodal,\n",
    "    bimodal or multimodal data. If requirements of the Rayleigh test are\n",
    "    met, the latter is more powerful.\n",
    "    :param alpha: sample of angles in radian\n",
    "    :param w:      number of incidences in case of binned angle data\n",
    "    :param sz:    step size for evaluating distribution, default 1 deg\n",
    "    :param axis:  compute along this dimension, default is None\n",
    "                  if axis=None, array is raveled\n",
    "    :return pval: two-tailed p-value\n",
    "    :return m:    minimum number of samples falling in one half of the circle\n",
    "    References: [Fisher1995]_, [Jammalamadaka2001]_, [Zar2009]_\n",
    "    \"\"\"\n",
    "\n",
    "    if w is None:\n",
    "        w = np.ones_like(alpha)\n",
    "\n",
    "    assert w.shape == alpha.shape, \"Dimensions of alpha and w must match\"\n",
    "\n",
    "    alpha = alpha % (2 * np.pi)\n",
    "    n = np.sum(w, axis=axis)\n",
    "\n",
    "    dg = np.arange(0, np.pi, np.radians(1))\n",
    "\n",
    "    m1 = np.zeros((len(dg),) + alpha.shape[1:])\n",
    "    m2 = np.zeros((len(dg),) + alpha.shape[1:])\n",
    "\n",
    "    for i, dg_val in enumerate(dg):\n",
    "        m1[i, ...] = np.sum(\n",
    "            w * ((alpha > dg_val) & (alpha < np.pi + dg_val)), axis=axis)\n",
    "        m2[i, ...] = n - m1[i, ...]\n",
    "\n",
    "    m = np.concatenate((m1, m2), axis=0).min(axis=axis)\n",
    "\n",
    "    n = np.atleast_1d(n)\n",
    "    m = np.atleast_1d(m)\n",
    "    A = np.empty_like(n)\n",
    "    pval = np.empty_like(n)\n",
    "    idx50 = (n > 50)\n",
    "\n",
    "    if np.any(idx50):\n",
    "        A[idx50] = np.pi * np.sqrt(n[idx50]) / 2 / (n[idx50] - 2 * m[idx50])\n",
    "        pval[idx50] = np.sqrt(2 * np.pi) / A[idx50] * \\\n",
    "                      np.exp(-np.pi ** 2 / 8 / A[idx50] ** 2)\n",
    "\n",
    "    if np.any(~idx50):\n",
    "        pval[~idx50] = 2 ** (1 - n[~idx50]) * (n[~idx50] - \\\n",
    "                                               2 * m[~idx50]) * sp_comb(n[~idx50], m[~idx50])\n",
    "\n",
    "    return pval.squeeze(), m\n",
    "\n",
    "\n",
    "def optimize_node (cp, p2, node):\n",
    "    # get 7 proposals for this node: stay the same, + and - for x, y, and time\n",
    "    # choose one with probability proportional to its L_local\n",
    "    # implement that one\n",
    "    pr_ctr = 0\n",
    "    axes = [0,1]\n",
    "    dirs = [1,-1]\n",
    "    proposals = [get_proposal(p2, pr_ctr, node, axis = 1, direction = 1, step = 0)]   # no change\n",
    "    for a in axes:\n",
    "        for d in dirs:\n",
    "            pr_ctr += 1\n",
    "            proposals.append(get_proposal(p2, pr_ctr, node, axis = a, \n",
    "                                          direction = d, step = cp.get_step(a)))\n",
    "    \n",
    "    L_temp = [((math.exp(pr.L))**(1/cp.exp_T)) for pr in proposals]\n",
    "    Ls = [a/sum(L_temp) for a in L_temp]\n",
    "    \n",
    "    accept = np.argmax(Ls)\n",
    "    \n",
    "    \n",
    "    p2 = accept_proposal(p2, cp, pr = proposals[accept])\n",
    "    return (p2)\n",
    "\n",
    "def optimize_node_v2 (cp, p2, node):\n",
    "    pr_ctr = 0\n",
    "    axes = [0, 1]\n",
    "    dirs = [1,-1]\n",
    "    proposals = [get_proposal(p2, cp, pr_ctr, node, axis = 1, direction = 1, step = 0)]   # no change\n",
    "    for a in axes:\n",
    "        for d in dirs:\n",
    "            pr_ctr += 1\n",
    "            proposals.append(get_proposal(p2, cp, pr_ctr, node, axis = a, \n",
    "                                          direction = d, step = cp.get_step(a)))\n",
    "    \n",
    "    for d in dirs:\n",
    "        pr_ctr += 1\n",
    "        st = cp.get_step(-1)\n",
    "        while (True):\n",
    "            temp = get_proposal(p2, cp, pr_ctr, node, axis = -1, direction = d, step = st)\n",
    "            if temp != None:\n",
    "                proposals.append(temp)\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                st/=2\n",
    "    \n",
    "    L_temp = [((math.exp(pr.L))**(1/math.exp(cp.exp_T))) for pr in proposals]\n",
    "    try:\n",
    "        Ls = [a/sum(L_temp) for a in L_temp]\n",
    "        \n",
    "    except ZeroDivisionError:\n",
    "        if (len(list(set(L_temp)))==1):\n",
    "            Ls = [1.0/len(L_temp) for a in L_temp]\n",
    "        else:\n",
    "            print ([pr.L for pr in proposals])\n",
    "            print (1/math.exp(cp.exp_T))\n",
    "            print (L_temp)\n",
    "            exit (0)\n",
    "    \n",
    "    if cp.acceptance == 'top':\n",
    "        accept = np.argmax(Ls)\n",
    "        \n",
    "    else:\n",
    "        if cp.acceptance == 'proportional':\n",
    "            accept = np.random.choice(a = range(len(proposals)), p = Ls)\n",
    "        \n",
    "    #if accept == 0:\n",
    "        #cp.sigma_T /= 2\n",
    "        #if cp.sigma_T < cp.opt_converge:\n",
    "        #    return (True, cp, p2)\n",
    "        \n",
    "        #else:\n",
    "        #    return (True, cp, p2) #change back to False\n",
    "    \n",
    "    #else:\n",
    "    p2 = accept_proposal(p2, cp, pr = proposals[accept])\n",
    "    return (True, cp, p2) #change back to False\n",
    "def plot_history (p):\n",
    "    #print ('*')\n",
    "    x = [a.location[0] for a in p.n2n.values()]\n",
    "    y = [a.location[1] for a in p.n2n.values()]\n",
    "\n",
    "    buffer = 5\n",
    "\n",
    "    plt.xlim(min(x)-buffer, max(x)+buffer)\n",
    "    plt.ylim(min(y)-buffer, max(y)+buffer)\n",
    "\n",
    "    for a in p.n2e.values():\n",
    "        try:\n",
    "            x1, y1 = a.anc.location\n",
    "            x2, y2 = a.desc.location\n",
    "            plt.plot([x1, x2],[y1,y2],'ro-')\n",
    "            \n",
    "        except AttributeError:\n",
    "            print (a.name, a.desc, a.anc, a.length)\n",
    "            exit(0)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return (None)\n",
    "\n",
    "\n",
    "def Ramanujan(n):\n",
    "    # Approximation for log (n!) given by Srinivasa Ramanujan\n",
    "    try:\n",
    "        return (n*math.log(n) - n + (math.log(n*(1+4*n*(1+2*n))))/6 \n",
    "            + math.log(math.pi)/2)\n",
    "    \n",
    "    except ValueError:\n",
    "        print (n)\n",
    "        exit(0)\n",
    "\n",
    "\n",
    "def simulate_evolution(i, psi, em_trans, fraction_mesenchymal, mutn_rate):\n",
    "    p = Phylogeny('Ph')\n",
    "    root_num = -1\n",
    "    i_temp = i\n",
    "    t_curr = 0\n",
    "    t = []   # list of coalescence times, from youngest to oldest\n",
    "    while (i>1):\n",
    "        ETi = (i*(i-1))/2.0   #mean (and variance) time to first coalescence for i lineages\n",
    "        t.append(t_curr+(np.random.exponential(1/ETi)))\n",
    "        i-=1\n",
    "        t_curr = t[-1]\n",
    "\n",
    "    t_max = max(t)\n",
    "    t = [t[i]/t_max for i in range(len(t))]\n",
    "    i = i_temp\n",
    "    p.psi = psi\n",
    "    p.em_trans = em_trans\n",
    "    p.migr_priors = [math.log(0.5),math.log(0.5)]\n",
    "    anc = [(0.0, 0.0), (0.0,0.0)]   # location of the ancestor to each tip so far\n",
    "    for x in range(i):   #create tip nodes, with dangling edges to be attached later\n",
    "        p.n2n[x]=Node('n'+str(x))\n",
    "        p.n2n[x].time = 0.0\n",
    "    p.n2n[root_num]=Node('n'+str(root_num))   # create root node\n",
    "    p.root = p.n2n[root_num]\n",
    "    p.root.time = t[-1]\n",
    "\n",
    "    for x in range(2):\n",
    "        new_name = 'e'+str(x)\n",
    "        p.n2e[x]=Edge(p, new_name, p.root, p.n2n[x])\n",
    "        p.n2n[x].anc_edge = p.n2e[x]\n",
    "        if np.random.uniform(0.0,1.0)<fraction_mesenchymal:\n",
    "            p.n2e[x].marginals = [-50.0, 0.0]    # using these temporarily to keep track of the migration\n",
    "                                               # state of each edge\n",
    "            \n",
    "        else:\n",
    "            p.n2e[x].marginals = [0.0, -50.0]\n",
    "\n",
    "    p.root.desc_edges = [p.n2e[0],p.n2e[1]]\n",
    "\n",
    "    n_counter = int(i)\n",
    "    e_counter = 2\n",
    "\n",
    "    Newick = '(0,1)'\n",
    "    hist = [anc]\n",
    "    i = 2   # the name of the tip to be added next\n",
    "    t_ct = -2   # the current time before present\n",
    "    g = []\n",
    "    while (i<i_temp):\n",
    "        b = t[t_ct+1]-t[t_ct] # time elapsed since last coalescent event\n",
    "        direction = [np.random.uniform(0,2*math.pi) for x in range(len(anc))]\n",
    "        try:\n",
    "            m_state = [np.argmax(p.n2n[n_temp].anc_edge.marginals) for n_temp in range(i)]\n",
    "            dist = [abs(np.random.normal(0.0,p.psi[m_state[x]]*(b**0.5))) for x in range(len(anc))]\n",
    "        except ValueError:\n",
    "            exit(0)\n",
    "            \n",
    "        anc_new = [(anc[x][0]+(math.cos(direction[x])*dist[x]),\n",
    "                    anc[x][1]+(math.sin(direction[x])*dist[x])) for x in range(len(anc))]\n",
    "        # anc_new is the positions of all lineages at this next coalescent event\n",
    "\n",
    "        g_new = random.randint(0,len(anc)-1)   # randomly select existing tip as sibling of new tip\n",
    "        g.append(g_new)\n",
    "        new_clade = '('+str(g_new)+','+str(len(anc))+')'\n",
    "        Newick = Newick.replace(str(g_new),new_clade)   # put this new clade into the Newick string\n",
    "\n",
    "        anc_new.append(anc_new[g_new])   # location of coalescent = where new edge starts\n",
    "        p.n2n[n_counter]=Node('n'+str(n_counter))   # new internal node\n",
    "        p.n2n[n_counter].location = anc_new[g_new]\n",
    "        p.n2n[n_counter].time = t[t_ct]\n",
    "        e_counter = insert_node(p, p.n2n[n_counter], p.n2n[i], p.n2n[g_new].anc_edge, e_counter)\n",
    "        n_counter+=1\n",
    "        anc = anc_new\n",
    "        hist.append(anc) # keep track of locations of lineages from previous coal. times\n",
    "\n",
    "        i+=1\n",
    "        t_ct-=1\n",
    "\n",
    "    b = t[0] \n",
    "    direction = [np.random.uniform(0,2*math.pi) for x in range(len(anc))]\n",
    "    try:\n",
    "        m_state = [np.argmax(p.n2n[n_temp].anc_edge.marginals) for n_temp in range(i)]\n",
    "        dist = [abs(np.random.normal(0.0,p.psi[m_state[x]]*(b**0.5))) for x in range(len(anc))]\n",
    "    except ValueError:\n",
    "        exit(0)\n",
    "\n",
    "    anc_new = [(anc[x][0]+(math.cos(direction[x])*dist[x]),\n",
    "                anc[x][1]+(math.sin(direction[x])*dist[x])) for x in range(len(anc))]\n",
    "    \n",
    "    hist.append(anc_new)\n",
    "    for a in range(len(anc_new)):\n",
    "        p.n2n[a].location = anc_new[a]\n",
    "\n",
    "    for i in p.n2e.values():\n",
    "        i.time = i.anc.time - i.desc.time\n",
    "        i.mutations = np.random.poisson(mutn_rate*i.time)\n",
    "        i.dist = (((i.anc.location[0]-i.desc.location[0])**2 +\n",
    "                          (i.anc.location[1]-i.desc.location[1])**2)**0.5)\n",
    "        \n",
    "    _ = plot_history (p)\n",
    "    \n",
    "    return (p)\n",
    "\n",
    "\n",
    "def to_root(cp, p, edge):\n",
    "        \"\"\"\n",
    "        Returns the total probability of all paths that lead to all descendant tips from starting this edge\n",
    "        in migration state k.\n",
    "        \"\"\"\n",
    "        if edge.desc.desc_edges == []:\n",
    "            edge.bk_anc = [(p.migr_priors[k] + emission(cp, edge, p.psi[k])) for k in range(p.psi_num)]\n",
    "            return (p, edge.bk_anc[:])\n",
    "        \n",
    "        else:\n",
    "            edge.bk_anc = [0.0 for i in range(p.psi_num)]\n",
    "            for desc_edge in edge.desc.desc_edges:     # for each descendant edge:\n",
    "                p, bk_temp = to_root(cp, p, desc_edge)     # get bk_anc for that edge\n",
    "                for j in range (p.psi_num):     # for each possible state at this edge:\n",
    "                    edge.bk_anc[j] += mult_logaddexp([(bk_temp[k]+p.em_trans.loc[j,k]) for k in range(p.psi_num)])\n",
    "                         # sum over the possible paths that lead to arriving at the end of this edge in state j\n",
    "                    edge.bk_anc[j] += emission(cp, edge, p.psi[j])\n",
    "                         # multiply by the probability that this edge was crossed in state j\n",
    "                    \n",
    "            if cp.now == True:\n",
    "                print (edge.name, edge.bk_anc, edge.bk_desc, edge.marginals)\n",
    "                        \n",
    "            return (p, edge.bk_anc[:])\n",
    "        \n",
    "def verify_psi(cp, p2):\n",
    "    direction = 1\n",
    "    step = 1\n",
    "    epsilon = 0.001\n",
    "    L_old = -10000\n",
    "    psi_temp = p2.psi[0]\n",
    "    while True:\n",
    "        L_tot = sum([emission(cp, e, psi_temp) for e in p2.n2e.values()])\n",
    "        if (abs(L_tot - L_old) < epsilon):\n",
    "            p2.psi[0] = psi_temp\n",
    "            return (p2)\n",
    "        \n",
    "        else:\n",
    "            if L_tot > L_old:\n",
    "                psi_temp += (direction*step)\n",
    "                \n",
    "            else:\n",
    "                direction *= -1\n",
    "                step /= 2\n",
    "                psi_temp += (direction*step)\n",
    "                \n",
    "            L_old = L_tot\n",
    "                            \n",
    "def build_phylogeny():\n",
    "    FILENAME = \"C:/Users/Brian/Desktop/tempdata/seg_locations.txt\"\n",
    "    temp = text_to_array(FILENAME)\n",
    "    temp = [i.split('\\t') for i in temp]\n",
    "    temp2 = np.array([[int(i[1]), int(i[2]), i[3]] for i in temp[1:]])\n",
    "    temp_colnames = [i[0] for i in temp[1:]]\n",
    "    temp3 = pd.DataFrame(temp2)\n",
    "    labels = {i-1:temp[i][0] for i in range(1, len(temp))}\n",
    "    locations = temp3.rename(index = labels, columns = {0:'x', 1:'y', 2:'duct'})\n",
    "\n",
    "    FILENAME = \"C:/Users/Brian/Desktop/tempdata/seg_height_2.txt\"\n",
    "\n",
    "    temp = text_to_array(FILENAME)\n",
    "    temp = [i.split('\\t') for i in temp]\n",
    "    heights = [float(temp[i][1]) for i in range(1, len(temp))]\n",
    "    #print (heights[:5])\n",
    "\n",
    "    FILENAME = \"C:/Users/Brian/Desktop/tempdata/seg_merge.txt\"\n",
    "\n",
    "    temp = text_to_array(FILENAME)\n",
    "    temp = [i.split('\\t') for i in temp[1:]]\n",
    "    merge = [[int(i[1]), int(i[2])] for i in temp]\n",
    "\n",
    "    pn = Phylogeny('pn')\n",
    "    n_ctr = 1\n",
    "    for i in range(len(labels)):\n",
    "        j = i+1\n",
    "        try:\n",
    "            temp = (int(locations.loc[labels[i],'x']), int(locations.loc[labels[i],'y']))\n",
    "            pn.n2n[-j] = Node('n'+str(-j))\n",
    "            pn.n2n[-j].location = temp\n",
    "            pn.n2n[-j].duct = locations.loc[labels[i],'duct']\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    merge_nodes = {}\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        j = i+1\n",
    "        if -j in pn.n2n.keys():\n",
    "            merge_nodes[-j] = pn.n2n[-j] \n",
    "\n",
    "    for i in range(len(merge)):\n",
    "        if merge[i][0] in merge_nodes.keys():\n",
    "            if merge[i][1] in merge_nodes.keys():\n",
    "                pn.n2n[i+1]=Node('n'+str(i+1))\n",
    "                n = pn.n2n[i+1]\n",
    "                d0 = merge_nodes[merge[i][0]]\n",
    "                d1 = merge_nodes[merge[i][1]]\n",
    "                n.time = heights[i]\n",
    "                e0 = Edge(pn, 'e'+str(pn.e_ctr), n, d0)\n",
    "                pn.n2e[pn.e_ctr]=e0\n",
    "                e1 = Edge(pn, 'e'+str(pn.e_ctr+1), n, d1)\n",
    "                pn.n2e[pn.e_ctr+1]=e1\n",
    "                d0.anc_edge = e0\n",
    "                d1.anc_edge = e1\n",
    "                n.desc_edges = [e0, e1]\n",
    "                pn.e_ctr += 2\n",
    "\n",
    "\n",
    "                merge_nodes[i+1]=n\n",
    "\n",
    "            else:\n",
    "                merge_nodes[i+1]=merge_nodes[merge[i][0]]\n",
    "\n",
    "        else:\n",
    "            if merge[i][1] in merge_nodes.keys():\n",
    "                merge_nodes[i+1]=merge_nodes[merge[i][1]]\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "    root = []\n",
    "    for i in pn.n2n.values():\n",
    "        if i.anc_edge == None:\n",
    "            root.append(i)\n",
    "\n",
    "    if len(root) == 1:\n",
    "        pn.root = root[0]\n",
    "\n",
    "    else:\n",
    "        print ('multiple roots')\n",
    "        exit(0)\n",
    "        \n",
    "    return(pn)\n",
    "\n",
    "\n",
    "def reconstruct (p, cp):\n",
    "    \"\"\"\n",
    "    a: Control_Panel object containing parameters for reconstruction\n",
    "    \"\"\"\n",
    "    p2 = clear_phylogeny (p, cp)\n",
    "    if cp.set_psi_num == 1:\n",
    "        p2.psi_num = 1\n",
    "        p2.psi = [1.0]\n",
    "        p2.em_trans = cp.em_trans_1\n",
    "        for e in p2.n2e.values():\n",
    "            e.normalized_marginals = [1.0]\n",
    "        \n",
    "    elif cp.set_psi_num == 2:\n",
    "        p2.psi_num = 2\n",
    "        p2.psi = [1.0, 1.0]\n",
    "        p2.migr_priors = [(cp.initial_percentage_epithelial/100), 1-(cp.initial_percentage_epithelial/100)]\n",
    "        p2.em_trans = cp.em_trans_2\n",
    "        for e in p2.n2e.values():\n",
    "            e.normalized_marginals = [0.5, 0.5]\n",
    "        \n",
    "    else:\n",
    "        print ('please set psi_num to 1 or 2')\n",
    "        exit(0)\n",
    "        \n",
    "    print (p2.psi_num)\n",
    "    #p2 = estimate_times(p2, cp)\n",
    "    if cp.initialize_locations == 'random':\n",
    "        p2 = initialize_locations_random (p2, cp)\n",
    "        \n",
    "    elif cp.initialize_locations == 'descendants':\n",
    "        p2 = initialize_locations_descendants (p2, cp)\n",
    "        \n",
    "    else:\n",
    "        print ('mode for initializing locations not recognized')\n",
    "        exit(0)\n",
    "        \n",
    "    if cp.omni == True:\n",
    "        p2 = initialize_angles_df(p2)\n",
    "        \n",
    "    p2 = initialize_psi (p2, cp)\n",
    "    p2 = fbb2(cp, p2)\n",
    "    p2, b, c = estimate_parameters(cp, p2)\n",
    "    p2, cp = initialize_sigmas (p2, cp)\n",
    "    num_edges = len(list(p2.n2e.values()))\n",
    "    cp.corr2 = 0.9\n",
    "    internal_nodes = [a for a in p2.n2n.values() if len(a.desc_edges) > 0]\n",
    "    iterations = 0\n",
    "    limit = cp.iter_limit\n",
    "    L_record = float('-inf')\n",
    "    L_old = float('-inf')\n",
    "    psi_old = p2.psi[:]\n",
    "    p2_old = copy.deepcopy(p2)\n",
    "    while (True):\n",
    "        iterations += 1\n",
    "        if (iterations > limit):\n",
    "            return p_record\n",
    "        \n",
    "        random.shuffle(internal_nodes)\n",
    "        for a in internal_nodes:\n",
    "            optimized, cp, p2 = optimize_node_v2 (cp, p2, a)\n",
    "        cp.sigma_T *= cp.sigma_T_step\n",
    "        p2 = fbb2(cp, p2)\n",
    "        p2, b, c = estimate_parameters(cp, p2)\n",
    "        if p2.L > L_record and iterations > 2:\n",
    "            p_record = copy.deepcopy(p2)\n",
    "            L_record = p2.L\n",
    "            \n",
    "        if (iterations%20 == 0):\n",
    "            print ('psi:',\"{:.2f}\".format(p2.psi[0]),\n",
    "                   'L: ',\"{:.2f}\".format(p2.L))\n",
    "        p2.migr_priors = b\n",
    "        p2.em_trans = c\n",
    "        p2_old = copy.deepcopy(p2)\n",
    "        cp.exp_T -= cp.exp_T_step\n",
    "        L_old = p2_old.L\n",
    "\n",
    "def initialize_control_panel (psi_n, iters):        \n",
    "    cp = Control_Panel()\n",
    "    cp.psi = [1000.0]\n",
    "    cp.em_trans_2 = pd.DataFrame(np.array([[math.log(0.975), math.log(0.025)],[math.log(0.025),math.log(0.975)]]))\n",
    "    cp.em_trans_1 = pd.DataFrame(np.array([math.log(1.000)]))\n",
    "    cp.migr_priors = [0.0]\n",
    "    cp.mutation_rate = [100.0]\n",
    "    cp.null_location = [0.0, 0.0]\n",
    "    cp.null_time = 0.0\n",
    "    cp.initialize_locations = 'random'\n",
    "    cp.L_epsilon = 0.1\n",
    "    cp.location_epsilon = 0.01\n",
    "    cp.initial_percentage_epithelial = 95\n",
    "    cp.psi_epsilon = 0.0001\n",
    "    cp.mutation_pseudocount = 0.001\n",
    "    cp.sigma_T = 1.0\n",
    "    cp.opt_converge = 0.01\n",
    "    cp.omni = False\n",
    "    cp.acceptance = 'proportional'\n",
    "    cp.exp_T_init = 1.0\n",
    "    cp.exp_T = cp.exp_T_init\n",
    "    cp.exp_T_stop = -3.0\n",
    "    cp.exp_T_step = (cp.exp_T_init - cp.exp_T_stop)/cp.iter_limit\n",
    "    cp.sigma_T_step = math.exp((math.log(0.01))/cp.iter_limit)\n",
    "    cp.correction = 0.0\n",
    "    cp.corr2 = 1.0\n",
    "    cp.iter_limit = iters\n",
    "    cp.set_psi_num = psi_n\n",
    "    \n",
    "    return (cp)\n",
    "\n",
    "psi_true = [50.0, 50.0]\n",
    "psi_e_to_mutn_ratio = 0.01\n",
    "print_flag = 0\n",
    "\n",
    "\n",
    "\n",
    "em = pd.DataFrame(np.array([[math.log(0.98), math.log(0.02)],[math.log(0.02),math.log(0.98)]]))\n",
    "\n",
    "p = simulate_evolution(i = 250, psi = psi_true, em_trans = em, fraction_mesenchymal = 0.05, \n",
    "                     mutn_rate = psi_true[0]/psi_e_to_mutn_ratio)\n",
    "\n",
    "for rep in range(1):\n",
    "    cp = initialize_control_panel (1, 750)\n",
    "    p_record= reconstruct (pn, cp)\n",
    "    print ('final estimate: ', p_record.psi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
